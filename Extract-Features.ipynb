{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features from MSR-VTT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir = './videos'\n",
    "output_dir = './frames'\n",
    "features_out = './features'\n",
    "jobs = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract frames from videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted and wrote 0 video files.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import os.path\n",
    "from subprocess import call\n",
    "from joblib import Parallel,delayed\n",
    "\n",
    "data_file = []\n",
    "\n",
    "def core_func(video_path):\n",
    "    global data_file\n",
    "    video_parts = get_video_parts(video_path)\n",
    "    filename_no_ext, filename = video_parts\n",
    "\n",
    "    # Only extract if we haven't done it yet. Otherwise, just get\n",
    "    # the info.\n",
    "    if not check_already_extracted(video_parts):\n",
    "        # Now extract it.\n",
    "        src = os.path.join(video_dir,filename)\n",
    "        dest = os.path.join(output_dir,filename_no_ext + '-%04d.jpg')\n",
    "        #print('in', src, dest)\n",
    "        call([\"ffmpeg\", \"-i\", src,\"-r\", \"4\", dest])\n",
    "    # Now get how many frames it is.\n",
    "    nb_frames = get_nb_frames_for_video(video_parts)\n",
    "    #print('written: ',nb_frames)\n",
    "    data_file.append([filename_no_ext, nb_frames])\n",
    "\n",
    "\n",
    "\n",
    "def get_nb_frames_for_video(video_parts):\n",
    "    \"\"\"Given video parts of an (assumed) already extracted video, return\n",
    "    the number of frames that were extracted.\"\"\"\n",
    "    filename_no_ext, _ = video_parts\n",
    "    generated_files = glob.glob(os.path.join(output_dir, filename_no_ext + '*.jpg'))\n",
    "    return len(generated_files)\n",
    "\n",
    "def get_video_parts(video_path):\n",
    "    \"\"\"Given a full path to a video, return its parts.\"\"\"\n",
    "    parts = video_path.split(os.path.sep)\n",
    "    #print(parts)\n",
    "    filename = parts[2]\n",
    "    filename_no_ext = filename.split('.')[0]\n",
    "    return filename_no_ext, filename\n",
    "\n",
    "def check_already_extracted(video_parts):\n",
    "    \"\"\"Check to see if we created the -0001 frame of this file.\"\"\"\n",
    "    filename_no_ext, _ = video_parts\n",
    "    return bool(os.path.exists(os.path.join(output_dir,\n",
    "                               filename_no_ext + '-0001.jpg')))\n",
    "\n",
    "\n",
    "\n",
    "vfiles = glob.glob(os.path.join(video_dir, '*.mp4'))\n",
    "results = Parallel(n_jobs=jobs)(delayed(core_func)(video_path) for video_path in vfiles)               \n",
    "\n",
    "with open('data_file.csv', 'w') as fout:\n",
    "    writer = csv.writer(fout)\n",
    "    writer.writerows(data_file)\n",
    "\n",
    "print(\"Extracted and wrote %d video files.\" % (len(data_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7351/7351 [1:08:43<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted and wrote 7351 video files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# data_file above did not work in parallel processing need to write a code to count them manually:\n",
    "from tqdm import tqdm\n",
    "pbar = tqdm(total=len(vfiles))\n",
    "\n",
    "data_file = []\n",
    "for video_path in vfiles:\n",
    "    video_parts = get_video_parts(video_path)\n",
    "    filename_no_ext, filename = video_parts\n",
    "    generated_files = glob.glob(os.path.join(output_dir, filename_no_ext + '*.jpg'))\n",
    "    data_file.append([filename_no_ext, len(generated_files)])\n",
    "    pbar.update(1)\n",
    "pbar.close()\n",
    "with open('data_file.csv', 'w') as fout:\n",
    "    writer = csv.writer(fout)\n",
    "    writer.writerows(data_file)\n",
    "\n",
    "print(\"Extracted and wrote %d video files.\" % (len(data_file)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video0.mp4\r\n"
     ]
    }
   ],
   "source": [
    "!ls DATA/videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video0-0001.jpg  video0-0075.jpg  video0-0149.jpg  video0-0223.jpg\r\n",
      "video0-0002.jpg  video0-0076.jpg  video0-0150.jpg  video0-0224.jpg\r\n",
      "video0-0003.jpg  video0-0077.jpg  video0-0151.jpg  video0-0225.jpg\r\n",
      "video0-0004.jpg  video0-0078.jpg  video0-0152.jpg  video0-0226.jpg\r\n",
      "video0-0005.jpg  video0-0079.jpg  video0-0153.jpg  video0-0227.jpg\r\n",
      "video0-0006.jpg  video0-0080.jpg  video0-0154.jpg  video0-0228.jpg\r\n",
      "video0-0007.jpg  video0-0081.jpg  video0-0155.jpg  video0-0229.jpg\r\n",
      "video0-0008.jpg  video0-0082.jpg  video0-0156.jpg  video0-0230.jpg\r\n",
      "video0-0009.jpg  video0-0083.jpg  video0-0157.jpg  video0-0231.jpg\r\n",
      "video0-0010.jpg  video0-0084.jpg  video0-0158.jpg  video0-0232.jpg\r\n",
      "video0-0011.jpg  video0-0085.jpg  video0-0159.jpg  video0-0233.jpg\r\n",
      "video0-0012.jpg  video0-0086.jpg  video0-0160.jpg  video0-0234.jpg\r\n",
      "video0-0013.jpg  video0-0087.jpg  video0-0161.jpg  video0-0235.jpg\r\n",
      "video0-0014.jpg  video0-0088.jpg  video0-0162.jpg  video0-0236.jpg\r\n",
      "video0-0015.jpg  video0-0089.jpg  video0-0163.jpg  video0-0237.jpg\r\n",
      "video0-0016.jpg  video0-0090.jpg  video0-0164.jpg  video0-0238.jpg\r\n",
      "video0-0017.jpg  video0-0091.jpg  video0-0165.jpg  video0-0239.jpg\r\n",
      "video0-0018.jpg  video0-0092.jpg  video0-0166.jpg  video0-0240.jpg\r\n",
      "video0-0019.jpg  video0-0093.jpg  video0-0167.jpg  video0-0241.jpg\r\n",
      "video0-0020.jpg  video0-0094.jpg  video0-0168.jpg  video0-0242.jpg\r\n",
      "video0-0021.jpg  video0-0095.jpg  video0-0169.jpg  video0-0243.jpg\r\n",
      "video0-0022.jpg  video0-0096.jpg  video0-0170.jpg  video0-0244.jpg\r\n",
      "video0-0023.jpg  video0-0097.jpg  video0-0171.jpg  video0-0245.jpg\r\n",
      "video0-0024.jpg  video0-0098.jpg  video0-0172.jpg  video0-0246.jpg\r\n",
      "video0-0025.jpg  video0-0099.jpg  video0-0173.jpg  video0-0247.jpg\r\n",
      "video0-0026.jpg  video0-0100.jpg  video0-0174.jpg  video0-0248.jpg\r\n",
      "video0-0027.jpg  video0-0101.jpg  video0-0175.jpg  video0-0249.jpg\r\n",
      "video0-0028.jpg  video0-0102.jpg  video0-0176.jpg  video0-0250.jpg\r\n",
      "video0-0029.jpg  video0-0103.jpg  video0-0177.jpg  video0-0251.jpg\r\n",
      "video0-0030.jpg  video0-0104.jpg  video0-0178.jpg  video0-0252.jpg\r\n",
      "video0-0031.jpg  video0-0105.jpg  video0-0179.jpg  video0-0253.jpg\r\n",
      "video0-0032.jpg  video0-0106.jpg  video0-0180.jpg  video0-0254.jpg\r\n",
      "video0-0033.jpg  video0-0107.jpg  video0-0181.jpg  video0-0255.jpg\r\n",
      "video0-0034.jpg  video0-0108.jpg  video0-0182.jpg  video0-0256.jpg\r\n",
      "video0-0035.jpg  video0-0109.jpg  video0-0183.jpg  video0-0257.jpg\r\n",
      "video0-0036.jpg  video0-0110.jpg  video0-0184.jpg  video0-0258.jpg\r\n",
      "video0-0037.jpg  video0-0111.jpg  video0-0185.jpg  video0-0259.jpg\r\n",
      "video0-0038.jpg  video0-0112.jpg  video0-0186.jpg  video0-0260.jpg\r\n",
      "video0-0039.jpg  video0-0113.jpg  video0-0187.jpg  video0-0261.jpg\r\n",
      "video0-0040.jpg  video0-0114.jpg  video0-0188.jpg  video0-0262.jpg\r\n",
      "video0-0041.jpg  video0-0115.jpg  video0-0189.jpg  video0-0263.jpg\r\n",
      "video0-0042.jpg  video0-0116.jpg  video0-0190.jpg  video0-0264.jpg\r\n",
      "video0-0043.jpg  video0-0117.jpg  video0-0191.jpg  video0-0265.jpg\r\n",
      "video0-0044.jpg  video0-0118.jpg  video0-0192.jpg  video0-0266.jpg\r\n",
      "video0-0045.jpg  video0-0119.jpg  video0-0193.jpg  video0-0267.jpg\r\n",
      "video0-0046.jpg  video0-0120.jpg  video0-0194.jpg  video0-0268.jpg\r\n",
      "video0-0047.jpg  video0-0121.jpg  video0-0195.jpg  video0-0269.jpg\r\n",
      "video0-0048.jpg  video0-0122.jpg  video0-0196.jpg  video0-0270.jpg\r\n",
      "video0-0049.jpg  video0-0123.jpg  video0-0197.jpg  video0-0271.jpg\r\n",
      "video0-0050.jpg  video0-0124.jpg  video0-0198.jpg  video0-0272.jpg\r\n",
      "video0-0051.jpg  video0-0125.jpg  video0-0199.jpg  video0-0273.jpg\r\n",
      "video0-0052.jpg  video0-0126.jpg  video0-0200.jpg  video0-0274.jpg\r\n",
      "video0-0053.jpg  video0-0127.jpg  video0-0201.jpg  video0-0275.jpg\r\n",
      "video0-0054.jpg  video0-0128.jpg  video0-0202.jpg  video0-0276.jpg\r\n",
      "video0-0055.jpg  video0-0129.jpg  video0-0203.jpg  video0-0277.jpg\r\n",
      "video0-0056.jpg  video0-0130.jpg  video0-0204.jpg  video0-0278.jpg\r\n",
      "video0-0057.jpg  video0-0131.jpg  video0-0205.jpg  video0-0279.jpg\r\n",
      "video0-0058.jpg  video0-0132.jpg  video0-0206.jpg  video0-0280.jpg\r\n",
      "video0-0059.jpg  video0-0133.jpg  video0-0207.jpg  video0-0281.jpg\r\n",
      "video0-0060.jpg  video0-0134.jpg  video0-0208.jpg  video0-0282.jpg\r\n",
      "video0-0061.jpg  video0-0135.jpg  video0-0209.jpg  video0-0283.jpg\r\n",
      "video0-0062.jpg  video0-0136.jpg  video0-0210.jpg  video0-0284.jpg\r\n",
      "video0-0063.jpg  video0-0137.jpg  video0-0211.jpg  video0-0285.jpg\r\n",
      "video0-0064.jpg  video0-0138.jpg  video0-0212.jpg  video0-0286.jpg\r\n",
      "video0-0065.jpg  video0-0139.jpg  video0-0213.jpg  video0-0287.jpg\r\n",
      "video0-0066.jpg  video0-0140.jpg  video0-0214.jpg  video0-0288.jpg\r\n",
      "video0-0067.jpg  video0-0141.jpg  video0-0215.jpg  video0-0289.jpg\r\n",
      "video0-0068.jpg  video0-0142.jpg  video0-0216.jpg  video0-0290.jpg\r\n",
      "video0-0069.jpg  video0-0143.jpg  video0-0217.jpg  video0-0291.jpg\r\n",
      "video0-0070.jpg  video0-0144.jpg  video0-0218.jpg  video0-0292.jpg\r\n",
      "video0-0071.jpg  video0-0145.jpg  video0-0219.jpg  video0-0293.jpg\r\n",
      "video0-0072.jpg  video0-0146.jpg  video0-0220.jpg\r\n",
      "video0-0073.jpg  video0-0147.jpg  video0-0221.jpg\r\n",
      "video0-0074.jpg  video0-0148.jpg  video0-0222.jpg\r\n"
     ]
    }
   ],
   "source": [
    "!ls frames/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract CNN Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Class for managing our data.\n",
    "\"\"\"\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import os.path\n",
    "import sys\n",
    "import operator\n",
    "import threading\n",
    "from keras.utils import np_utils\n",
    "\n",
    "class threadsafe_iterator:\n",
    "    def __init__(self, iterator):\n",
    "        self.iterator = iterator\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            return next(self.iterator)\n",
    "\n",
    "def threadsafe_generator(func):\n",
    "    \"\"\"Decorator\"\"\"\n",
    "    def gen(*a, **kw):\n",
    "        return threadsafe_iterator(func(*a, **kw))\n",
    "    return gen\n",
    "\n",
    "class DataSet():\n",
    "\n",
    "    def __init__(self, seq_length=40, class_limit=None, image_shape=(224, 224, 3)):\n",
    "        \"\"\"Constructor.\n",
    "        seq_length = (int) the number of frames to consider\n",
    "        class_limit = (int) number of classes to limit the data to.\n",
    "            None = no limit.\n",
    "        \"\"\"\n",
    "        self.seq_length = seq_length\n",
    "        self.class_limit = class_limit\n",
    "        self.sequence_path = os.path.join('data', 'sequences')\n",
    "        self.max_frames = 1000  # max number of frames a video can have for us to use it\n",
    "\n",
    "        # Get the data.\n",
    "        self.data = self.get_data()\n",
    "\n",
    "        # Now do some minor data cleaning.\n",
    "        self.data = self.clean_data()\n",
    "\n",
    "        self.image_shape = image_shape\n",
    "\n",
    "    @staticmethod\n",
    "    def get_data():\n",
    "        \"\"\"Load our data from file.\"\"\"\n",
    "        with open(os.path.join('data_file.csv'), 'r') as fin:\n",
    "            reader = csv.reader(fin)\n",
    "            data = list(reader)\n",
    "            #print(len(data))\n",
    "\n",
    "        return data\n",
    "\n",
    "    def clean_data(self):\n",
    "        \"\"\"Limit samples to greater than the sequence length and fewer\n",
    "        than N frames. Also limit it to classes we want to use.\"\"\"\n",
    "        data_clean = []\n",
    "        for item in self.data:\n",
    "            if int(item[1]) >= self.seq_length and int(item[1]) <= self.max_frames:\n",
    "                data_clean.append(item)\n",
    "\n",
    "        return data_clean\n",
    "\n",
    "\n",
    "    def build_image_sequence(self, frames):\n",
    "        \"\"\"Given a set of frames (filenames), build our sequence.\"\"\"\n",
    "        return [process_image(x, self.image_shape) for x in frames]\n",
    "\n",
    "    def get_extracted_sequence(self, data_type, sample):\n",
    "        \"\"\"Get the saved extracted features.\"\"\"\n",
    "        filename = sample[2]\n",
    "        path = os.path.join(self.sequence_path, filename + '-' + str(self.seq_length) + \\\n",
    "            '-' + data_type + '.npy')\n",
    "        if os.path.isfile(path):\n",
    "            return np.load(path)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_frames_for_sample(sample):\n",
    "        \"\"\"Given a sample row from the data file, get all the corresponding frame\n",
    "        filenames.\"\"\"\n",
    "        filename = sample[0]\n",
    "        images = sorted(glob.glob(os.path.join(output_dir, filename + '*jpg')))\n",
    "        return images\n",
    "\n",
    "    @staticmethod\n",
    "    def get_filename_from_image(filename):\n",
    "        parts = filename.split(os.path.sep)\n",
    "        return parts[-1].replace('.jpg', '')\n",
    "\n",
    "    @staticmethod\n",
    "    def rescale_list(input_list, size):\n",
    "        \"\"\"Given a list and a size, return a rescaled/samples list. For example,\n",
    "        if we want a list of size 5 and we have a list of size 25, return a new\n",
    "        list of size five which is every 5th element of the origina list.\"\"\"\n",
    "        assert len(input_list) >= size\n",
    "\n",
    "        # Get the number to skip between iterations.\n",
    "        skip = len(input_list) // size\n",
    "\n",
    "        # Build our new output.\n",
    "        output = [input_list[i] for i in range(0, len(input_list), skip)]\n",
    "\n",
    "        # Cut off the last one if needed.\n",
    "        return output[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "import numpy as np\n",
    "\n",
    "def process_image(image, target_shape):\n",
    "    \"\"\"Given an image, process it and return the array.\"\"\"\n",
    "    # Load the image.\n",
    "    h, w, _ = target_shape\n",
    "    image = load_img(image, target_size=(h, w))\n",
    "\n",
    "    # Turn it into numpy, normalize and return.\n",
    "    img_arr = img_to_array(image)\n",
    "    x = (img_arr / 255.).astype(np.float32)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "import numpy as np\n",
    "\n",
    "class Extractor():\n",
    "    def __init__(self, weights=None):\n",
    "        \"\"\"Either load pretrained from imagenet, or load our saved\n",
    "        weights from our own training.\"\"\"\n",
    "\n",
    "        self.weights = weights  # so we can check elsewhere which model\n",
    "\n",
    "        if weights is None:\n",
    "            # Get model with pretrained weights.\n",
    "            base_model = InceptionV3(\n",
    "                weights='imagenet',\n",
    "                include_top=True\n",
    "            )\n",
    "\n",
    "            # We'll extract features at the final pool layer.\n",
    "            self.model = Model(\n",
    "                inputs=base_model.input,\n",
    "                outputs=base_model.get_layer('avg_pool').output\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            # Load the model first.\n",
    "            self.model = load_model(weights)\n",
    "\n",
    "            # Then remove the top so we get features not predictions.\n",
    "            # From: https://github.com/fchollet/keras/issues/2371\n",
    "            self.model.layers.pop()\n",
    "            self.model.layers.pop()  # two pops to get to pool layer\n",
    "            self.model.outputs = [self.model.layers[-1].output]\n",
    "            self.model.output_layers = [self.model.layers[-1]]\n",
    "            self.model.layers[-1].outbound_nodes = []\n",
    "\n",
    "    def extract(self, image_path):\n",
    "        img = image.load_img(image_path, target_size=(299, 299))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        # Get the prediction.\n",
    "        features = self.model.predict(x)\n",
    "\n",
    "        if self.weights is None:\n",
    "            # For imagenet/default network:\n",
    "            features = features[0]\n",
    "        else:\n",
    "            # For loaded network:\n",
    "            features = features[0]\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/7273 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 7273/7273 [4:23:07<00:00,  2.11s/it]  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os.path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set defaults.\n",
    "seq_length = 30\n",
    "class_limit = None  # Number of classes to extract. Can be 1-101 or None for all.\n",
    "\n",
    "# Get the dataset.\n",
    "data = DataSet(seq_length=seq_length, class_limit=class_limit)\n",
    "\n",
    "# get the model.\n",
    "model = Extractor()\n",
    "\n",
    "print(len(data.data))\n",
    "# Loop through data.\n",
    "pbar = tqdm(total=len(data.data))\n",
    "for video in data.data:\n",
    "\n",
    "    # Get the path to the sequence for this video.\n",
    "    path = os.path.join(features_out, video[0] + '-' + str(seq_length) + \\\n",
    "        '-features')  # numpy will auto-append .npy\n",
    "\n",
    "    # Check if we already have it.\n",
    "    if os.path.isfile(path):\n",
    "        pbar.update(1)\n",
    "        continue\n",
    "\n",
    "    # Get the frames for this video.\n",
    "    frames = data.get_frames_for_sample(video)\n",
    "\n",
    "    # Now downsample to just the ones we need.\n",
    "    frames = data.rescale_list(frames, seq_length)\n",
    "\n",
    "    # Now loop through and extract features to build the sequence.\n",
    "    sequence = []\n",
    "    for frame in frames:\n",
    "        features = model.extract(frame)\n",
    "        sequence.append(features)\n",
    "\n",
    "    # Save the sequence.\n",
    "    np.save(path, sequence)\n",
    "    \n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mThe directory '/home/narain.adithya/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mThe directory '/home/narain.adithya/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting h5py\n",
      "  Downloading h5py-2.7.1-cp35-cp35m-manylinux1_x86_64.whl (5.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.3MB 286kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): numpy>=1.7 in /usr/local/lib/python3.5/dist-packages (from h5py)\n",
      "Requirement already satisfied (use --upgrade to upgrade): six in /usr/lib/python3/dist-packages (from h5py)\n",
      "Installing collected packages: h5py\n",
      "Successfully installed h5py-2.7.1\n",
      "\u001b[33mYou are using pip version 8.1.1, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!sudo pip3 install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  hdf5-helpers libaec-dev libaec0 libgfortran3 libhdf5-10 libhdf5-cpp-11\n",
      "  libjpeg-dev libjpeg-turbo8-dev libjpeg8-dev libsz2 zlib1g-dev\n",
      "Suggested packages:\n",
      "  libhdf5-doc\n",
      "The following NEW packages will be installed:\n",
      "  hdf5-helpers libaec-dev libaec0 libgfortran3 libhdf5-10 libhdf5-cpp-11\n",
      "  libhdf5-dev libjpeg-dev libjpeg-turbo8-dev libjpeg8-dev libsz2 zlib1g-dev\n",
      "0 upgraded, 12 newly installed, 0 to remove and 0 not upgraded.\n",
      "Need to get 6,837 kB of archives.\n",
      "After this operation, 37.9 MB of additional disk space will be used.\n",
      "Do you want to continue? [Y/n] ^C\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install libhdf5-dev"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
