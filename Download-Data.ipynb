{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to Download MSR-VTT dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os, os.path\n",
    "\n",
    "train_val = json.load(open('videodatainfo_2017.json', 'r'))\n",
    "\n",
    "\n",
    "# combine all images and annotations together\n",
    "videos = train_val['videos']\n",
    "sentences = train_val['sentences']\n",
    "\n",
    "# for efficiency lets group annotations by image\n",
    "itoa = {}\n",
    "for s in sentences:\n",
    "    videoid_buf = s['video_id']\n",
    "    videoid = int(videoid_buf[5:])\n",
    "    if not videoid in itoa: itoa[videoid] = []\n",
    "    itoa[videoid].append(s)\n",
    "\n",
    "f = open('videos_list.csv', 'w')\n",
    "# create a csv containing video\n",
    "for i,img in enumerate(videos):\n",
    "    line = str(img[\"video_id\"])+','+img['url']+','+str(img['start time'])+','+str(img['end time'])+','+str(img['category'])+'\\n'\n",
    "    #print(line)\n",
    "    f.write(line)\n",
    "f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video0,https://www.youtube.com/watch?v=9lZi22qLlEo,137.72,149.44,9\r\n",
      "video1,https://www.youtube.com/watch?v=w4JM08PDEng,184.33,206.89,16\r\n",
      "video2,https://www.youtube.com/watch?v=QA7KVQq9vKA,31.17,41.24,9\r\n",
      "video3,https://www.youtube.com/watch?v=QFmJZ0GU6yc,48.26,58.51,8\r\n",
      "video4,https://www.youtube.com/watch?v=2q-dONPhzis,268.58,278.83,14\r\n",
      "video5,https://www.youtube.com/watch?v=b-3_7iglTbg,0.0,30.0,13\r\n",
      "video6,https://www.youtube.com/watch?v=YvF-ZTH28yI,143.93,160.97,13\r\n",
      "video7,https://www.youtube.com/watch?v=y6sBoW139Sc,81.06,92.61,17\r\n",
      "video8,https://www.youtube.com/watch?v=X-aaASj9-u0,0.0,30.0,3\r\n",
      "video9,https://www.youtube.com/watch?v=oxswNqeujeY,0.0,30.0,5\r\n"
     ]
    }
   ],
   "source": [
    "!head videos_list.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import fnmatch\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import uuid\n",
    "\n",
    "from joblib import delayed\n",
    "from joblib import Parallel\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_video_folders(dataset, output_dir, tmp_dir):\n",
    "    \"\"\"Creates a directory for each label name in the dataset.\"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    if not os.path.exists(tmp_dir):\n",
    "        os.makedirs(tmp_dir)\n",
    "\n",
    "    label_to_dir = {}\n",
    "    for label_name in dataset['label-name'].unique():\n",
    "        this_dir = os.path.join(output_dir, label_name)\n",
    "        if not os.path.exists(this_dir):\n",
    "            os.makedirs(this_dir)\n",
    "        label_to_dir[label_name] = this_dir\n",
    "    return label_to_dir\n",
    "\n",
    "\n",
    "def construct_video_filename(row, label_to_dir, trim_format='%06d'):\n",
    "    \"\"\"Given a dataset row, this function constructs the \n",
    "       output filename for a given video.\n",
    "    \"\"\"\n",
    "\n",
    "    base_name = row['video-id']+'.mp4'\n",
    "    output_filename = os.path.join(label_to_dir,base_name)\n",
    "    return output_filename\n",
    "\n",
    "\n",
    "def download_clip(video_identifier, output_filename,\n",
    "                  start_time, end_time, \n",
    "                  tmp_dir='/tmp/kinetics',\n",
    "                  num_attempts=5,\n",
    "                  url_base='https://www.youtube.com/watch?v='):\n",
    "    \"\"\"Download a video from youtube if exists and is not blocked.\n",
    "    \n",
    "    arguments:\n",
    "    ---------\n",
    "    video_identifier: str\n",
    "        Unique YouTube video identifier (11 characters)\n",
    "    output_filename: str\n",
    "        File path where the video will be stored.\n",
    "    start_time: float\n",
    "        Indicates the begining time in seconds from where the video \n",
    "        will be trimmed.\n",
    "    end_time: float\n",
    "        Indicates the ending time in seconds of the trimmed video.\n",
    "    \"\"\"\n",
    "    # Defensive argument checking.\n",
    "    assert isinstance(video_identifier, str), 'video_identifier must be string'\n",
    "    assert isinstance(output_filename, str), 'output_filename must be string'\n",
    "    status = False\n",
    "    # Construct command line for getting the direct video link.\n",
    "    tmp_filename = os.path.join(tmp_dir,\n",
    "                                '%s.%%(ext)s' % uuid.uuid4())\n",
    "    command = ['youtube-dl',\n",
    "               '--quiet', '--no-warnings',\n",
    "               '-f', 'mp4',\n",
    "               '-o', '\"%s\"' % tmp_filename, \n",
    "               '\"%s\"' % (video_identifier)]\n",
    "    command = ' '.join(command)\n",
    "    attempts = 0\n",
    "    while True:\n",
    "        try:\n",
    "            output = subprocess.check_output(command, shell=True, \n",
    "                                             stderr=subprocess.STDOUT)\n",
    "        except subprocess.CalledProcessError as err:\n",
    "            attempts += 1\n",
    "            if attempts == num_attempts:\n",
    "                return status, err.output\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    tmp_filename = glob.glob('%s*' % tmp_filename.split('.')[0])[0]\n",
    "    # Construct command to trim the videos (ffmpeg required).\n",
    "    command = ['ffmpeg',\n",
    "               '-i', '\"%s\"' % tmp_filename,\n",
    "               '-ss', str(start_time),\n",
    "               '-t', str(end_time - start_time),\n",
    "               '-c:v', 'libx264', '-c:a', 'copy',\n",
    "               '-threads', '1',\n",
    "               '-loglevel', 'panic',\n",
    "               '\"%s\"' % output_filename]\n",
    "    command = ' '.join(command)\n",
    "    try:\n",
    "        output = subprocess.check_output(command, shell=True,\n",
    "                                         stderr=subprocess.STDOUT)\n",
    "    except subprocess.CalledProcessError as err:\n",
    "        return status, err.output\n",
    "\n",
    "    # Check if the video was successfully saved.\n",
    "    status = os.path.exists(output_filename)\n",
    "    os.remove(tmp_filename)\n",
    "    return status, 'Downloaded'\n",
    "\n",
    "\n",
    "def download_clip_wrapper(row, label_to_dir, trim_format, tmp_dir):\n",
    "    \"\"\"Wrapper for parallel processing purposes.\"\"\"\n",
    "    output_filename = construct_video_filename(row, label_to_dir,\n",
    "                                               trim_format)\n",
    "    clip_id = os.path.basename(output_filename).split('.mp4')[0]\n",
    "    if os.path.exists(output_filename):\n",
    "        status = tuple([clip_id, True, 'Exists'])\n",
    "        return status\n",
    "\n",
    "    downloaded, log = download_clip(row['url'], output_filename,\n",
    "                                    row['start-time'], row['end-time'],\n",
    "                                    tmp_dir=tmp_dir)\n",
    "    status = tuple([clip_id, downloaded, log])\n",
    "    return status\n",
    " \n",
    "\n",
    "def parse_kinetics_annotations(input_csv):\n",
    "    \"\"\"Returns a parsed DataFrame.\n",
    "    \n",
    "    arguments:\n",
    "    ---------\n",
    "    input_csv: str\n",
    "        Path to CSV file containing the following columns:\n",
    "          'YouTube Identifier,Start time,End time,Class label'\n",
    "    returns:\n",
    "    -------\n",
    "    dataset: DataFrame\n",
    "        Pandas with the following columns:\n",
    "            'video-id', 'start-time', 'end-time', 'label-name'\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(input_csv, names=['video-id', 'url', 'start-time', 'end-time', 'label-name'], dtype={'video-id':str, 'url':str, 'start-time':float, 'end-time':float, 'label-name':int})\n",
    "    #df.rename(columns={'youtube_id': 'video-id',\n",
    "    #                   'time_start': 'start-time',\n",
    "    #                   'time_end': 'end-time',\n",
    "    #                   'label': 'label-name',\n",
    "    #                   'is_cc': 'is-cc'}, inplace=True)\n",
    "    return df\n",
    "\n",
    "def main(input_csv, output_dir,\n",
    "         trim_format='%06d', num_jobs=24, tmp_dir='temp'):\n",
    "\n",
    "    # Reading and parsing Kinetics.\n",
    "    dataset = parse_kinetics_annotations(input_csv)\n",
    "    dataset.head()\n",
    "\n",
    "\n",
    "    # Creates folders where videos will be saved later.\n",
    "    #label_to_dir = create_video_folders(dataset, output_dir, tmp_dir)\n",
    "    label_to_dir = output_dir\n",
    "\n",
    "    # Download all clips.\n",
    "    if num_jobs==1:\n",
    "        status_lst = []\n",
    "        for i, row in dataset.iterrows():\n",
    "            status_lst.append(download_clip_wrapper(row, label_to_dir, \n",
    "                                                    trim_format, tmp_dir))\n",
    "    else:\n",
    "        status_lst = Parallel(n_jobs=num_jobs)(delayed(download_clip_wrapper)(\n",
    "            row, label_to_dir,\n",
    "            trim_format, tmp_dir) for i, row in dataset.iterrows())\n",
    "\n",
    "    # Clean tmp dir.\n",
    "    shutil.rmtree(tmp_dir)\n",
    "\n",
    "    # Save download report.\n",
    "    with open('download_report.json', 'w') as fobj:\n",
    "        #print(status_lst)\n",
    "        fobj.write(json.dumps(status_lst))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(input_csv='videos_list.csv', output_dir='videos', num_jobs=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
